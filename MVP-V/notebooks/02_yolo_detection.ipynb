{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MVP-V: YOLO 객체 탐지\n",
        "\n",
        "이 노트북은 YOLOv8/v11을 사용하여 KITTI 데이터셋에서 객체 탐지를 수행합니다.\n",
        "\n",
        "## 목표\n",
        "- YOLOv8/v11 모델 로드 (사전학습 또는 KITTI fine-tuning)\n",
        "- 추론 및 결과 시각화\n",
        "- (선택) SAM을 활용한 pseudo-label 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: 라이브러리 설치 및 임포트\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "\n",
        "# 경로 설정\n",
        "project_root = Path.cwd().parent.parent\n",
        "dataset_root = project_root / \"dataset\" / \"kitti\"\n",
        "print(f\"프로젝트 루트: {project_root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: YOLO 모델 로드\n",
        "# YOLOv8 또는 YOLOv11 중 선택\n",
        "model_name = 'yolov8n.pt'  # nano 버전 (빠른 추론), 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt' 사용 가능\n",
        "# 또는 'yolo11n.pt' 등 최신 버전 사용 가능\n",
        "\n",
        "model = YOLO(model_name)\n",
        "print(f\"모델 로드 완료: {model_name}\")\n",
        "print(f\"모델 클래스 수: {len(model.names)}\")\n",
        "print(f\"모델 클래스: {model.names}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: KITTI 데이터에 맞게 모델 Fine-tuning (선택사항)\n",
        "# KITTI 데이터로 fine-tuning하려면 아래 코드 사용\n",
        "# train_images_dir = dataset_root / \"images\" / \"train\"\n",
        "# train_labels_dir = dataset_root / \"labels\" / \"train\"\n",
        "# \n",
        "# if train_images_dir.exists():\n",
        "#     results = model.train(\n",
        "#         data=str(dataset_root / \"kitti.yaml\"),  # KITTI 데이터셋 설정 파일\n",
        "#         epochs=50,\n",
        "#         imgsz=640,\n",
        "#         batch=16,\n",
        "#         name='yolo_kitti'\n",
        "#     )\n",
        "# else:\n",
        "#     print(\"훈련 데이터를 찾을 수 없습니다. 사전학습 모델을 사용합니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: 단일 이미지 추론\n",
        "def predict_image(model, image_path, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    단일 이미지에 대한 YOLO 추론\n",
        "    \"\"\"\n",
        "    results = model(image_path, conf=conf_threshold)\n",
        "    return results[0]\n",
        "\n",
        "# 테스트 이미지 로드\n",
        "train_images_dir = dataset_root / \"images\" / \"train\"\n",
        "if train_images_dir.exists():\n",
        "    image_files = sorted(train_images_dir.glob(\"*.png\"))\n",
        "    if image_files:\n",
        "        test_image_path = image_files[0]\n",
        "        print(f\"테스트 이미지: {test_image_path.name}\")\n",
        "        \n",
        "        # 추론 실행\n",
        "        results = predict_image(model, str(test_image_path))\n",
        "        \n",
        "        # 결과 출력\n",
        "        print(f\"\\n탐지된 객체 수: {len(results.boxes)}\")\n",
        "        for i, box in enumerate(results.boxes):\n",
        "            class_id = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            class_name = model.names[class_id]\n",
        "            print(f\"  객체 {i+1}: {class_name} (신뢰도: {conf:.2f})\")\n",
        "    else:\n",
        "        print(\"이미지 파일을 찾을 수 없습니다.\")\n",
        "else:\n",
        "    print(\"이미지 디렉토리를 찾을 수 없습니다.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: 결과 시각화\n",
        "def visualize_yolo_results(image_path, results, save_path=None):\n",
        "    \"\"\"\n",
        "    YOLO 추론 결과 시각화\n",
        "    \"\"\"\n",
        "    # 이미지 로드\n",
        "    image = cv2.imread(str(image_path))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # YOLO의 내장 시각화 함수 사용\n",
        "    annotated_image = results.plot()\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "    axes[0].imshow(image)\n",
        "    axes[0].set_title(\"원본 이미지\", fontsize=14)\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    axes[1].imshow(annotated_image)\n",
        "    axes[1].set_title(\"YOLO 탐지 결과\", fontsize=14)\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    \n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "# 시각화 실행\n",
        "if 'results' in locals() and 'test_image_path' in locals():\n",
        "    fig = visualize_yolo_results(test_image_path, results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: 배치 추론 및 결과 저장\n",
        "def batch_predict(model, image_dir, output_dir=None, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    여러 이미지에 대한 배치 추론\n",
        "    \"\"\"\n",
        "    image_files = sorted(image_dir.glob(\"*.png\"))\n",
        "    all_results = []\n",
        "    \n",
        "    print(f\"총 {len(image_files)}개 이미지 처리 중...\")\n",
        "    for i, image_path in enumerate(image_files):\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"진행: {i+1}/{len(image_files)}\")\n",
        "        \n",
        "        results = model(str(image_path), conf=conf_threshold)\n",
        "        all_results.append((image_path.name, results[0]))\n",
        "    \n",
        "    print(f\"완료: {len(all_results)}개 이미지 처리됨\")\n",
        "    return all_results\n",
        "\n",
        "# 배치 추론 실행 (선택사항 - 시간이 오래 걸릴 수 있음)\n",
        "# if train_images_dir.exists():\n",
        "#     batch_results = batch_predict(model, train_images_dir, conf_threshold=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: SAM 설치 및 사용 (선택사항)\n",
        "# SAM2를 사용하려면 다음 설치 필요:\n",
        "# !pip install git+https://github.com/facebookresearch/segment-anything-2.git\n",
        "\n",
        "# from sam2.build_sam import build_sam2\n",
        "# from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "# \n",
        "# # SAM2 모델 로드\n",
        "# sam2_checkpoint = \"sam2_hiera_large.pt\"  # 체크포인트 다운로드 필요\n",
        "# sam2_cfg_file = \"sam2_hiera_l.yaml\"\n",
        "# sam2 = build_sam2(sam2_cfg_file, sam2_checkpoint, device='cuda')\n",
        "# sam2_predictor = SAM2ImagePredictor(sam2)\n",
        "# \n",
        "# # YOLO 탐지 결과를 SAM 프롬프트로 사용\n",
        "# # YOLO 박스 → SAM 세그멘테이션 마스크 생성\n",
        "# def yolo_to_sam_masks(image_path, yolo_results, sam_predictor):\n",
        "#     image = cv2.imread(str(image_path))\n",
        "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "#     sam_predictor.set_image(image)\n",
        "#     \n",
        "#     masks = []\n",
        "#     for box in yolo_results.boxes:\n",
        "#         bbox = box.xyxy[0].cpu().numpy()\n",
        "#         mask, scores, logits = sam_predictor.predict(box=bbox)\n",
        "#         masks.append(mask)\n",
        "#     \n",
        "#     return masks"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
