{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cell 1: ë…¸íŠ¸ë¶ ê°œìš”\n",
                "\n",
                "## 05_bc_training.ipynb - í–‰ë™ í´ë¡œë‹ í•™ìŠµ\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” CARLAì—ì„œ ìˆ˜ì§‘í•œ Expert ë°ì´í„°ë¡œ í–‰ë™ í´ë¡œë‹(Behavior Cloning)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
                "\n",
                "### ëª©í‘œ\n",
                "1. CARLA ìˆ˜ì§‘ ë°ì´í„° ë¡œë“œ\n",
                "2. ì‚¬ì „í•™ìŠµëœ Vision Encoder í™œìš©\n",
                "3. Policy Head í•™ìŠµ\n",
                "4. ëª¨ë¸ í‰ê°€\n",
                "\n",
                "### ì°¸ê³  ë…¼ë¬¸\n",
                "- **ALVINN** (Pomerleau, 1988): ìµœì´ˆì˜ End-to-end ììœ¨ì£¼í–‰\n",
                "- **End-to-End Learning** (Bojarski et al., 2016): NVIDIA PilotNet\n",
                "- **DAgger** (Ross et al., 2011): Distribution shift ë¬¸ì œ í•´ê²°"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •\n",
                "\n",
                "import sys\n",
                "import os\n",
                "import json\n",
                "import glob\n",
                "import logging\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import cv2\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "from tqdm.notebook import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torch.cuda.amp import autocast, GradScaler\n",
                "import torchvision.transforms as T\n",
                "import torchvision.models as models\n",
                "\n",
                "# í”„ë¡œì íŠ¸ ë£¨íŠ¸\n",
                "PROJECT_ROOT = Path().absolute().parent\n",
                "sys.path.insert(0, str(PROJECT_ROOT))\n",
                "\n",
                "# ë¡œê¹… ì„¤ì •\n",
                "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "# GPU í™•ì¸\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: ì„¤ì • ë¡œë“œ\n",
                "\n",
                "import yaml\n",
                "\n",
                "# ì„¤ì • íŒŒì¼ ë¡œë“œ\n",
                "with open(PROJECT_ROOT / 'config' / 'training_config.yaml', 'r', encoding='utf-8') as f:\n",
                "    training_config = yaml.safe_load(f)\n",
                "\n",
                "with open(PROJECT_ROOT / 'config' / 'model_config.yaml', 'r', encoding='utf-8') as f:\n",
                "    model_config = yaml.safe_load(f)\n",
                "\n",
                "# BC í•™ìŠµ ì„¤ì •\n",
                "BC_CONFIG = training_config['bc_training']\n",
                "print(\"í–‰ë™ í´ë¡œë‹ í•™ìŠµ ì„¤ì •:\")\n",
                "for key, value in BC_CONFIG.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: CARLA ìˆ˜ì§‘ ë°ì´í„° ë¡œë“œ\n",
                "\n",
                "CARLA_DATA_DIR = PROJECT_ROOT / 'dataset' / 'carla_collected'\n",
                "\n",
                "# ì—í”¼ì†Œë“œ ë””ë ‰í† ë¦¬ ì°¾ê¸°\n",
                "episode_dirs = sorted(glob.glob(str(CARLA_DATA_DIR / 'episode_*')))\n",
                "\n",
                "if episode_dirs:\n",
                "    print(f\"CARLA ìˆ˜ì§‘ ì—í”¼ì†Œë“œ: {len(episode_dirs)}ê°œ\")\n",
                "    \n",
                "    # ì „ì²´ ë°ì´í„° ë¡œë“œ\n",
                "    all_frames = []\n",
                "    for ep_dir in tqdm(episode_dirs, desc=\"ë°ì´í„° ë¡œë“œ\"):\n",
                "        parquet_path = Path(ep_dir) / 'frames.parquet'\n",
                "        if parquet_path.exists():\n",
                "            df = pd.read_parquet(parquet_path)\n",
                "            df['episode_dir'] = ep_dir\n",
                "            all_frames.append(df)\n",
                "    \n",
                "    if all_frames:\n",
                "        data_df = pd.concat(all_frames, ignore_index=True)\n",
                "        print(f\"\\nì´ í”„ë ˆì„: {len(data_df):,}\")\n",
                "        print(f\"ì»¬ëŸ¼: {list(data_df.columns)}\")\n",
                "    else:\n",
                "        print(\"âš ï¸ ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
                "        data_df = pd.DataFrame()\n",
                "else:\n",
                "    print(\"âš ï¸ CARLA ìˆ˜ì§‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
                "    print(\"02_data_collection.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
                "    data_df = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„ì„\n",
                "\n",
                "if len(data_df) > 0:\n",
                "    # ì¶©ëŒ/ì°¨ì„ ì¹¨ë²” ë°ì´í„° ì œì™¸ (ì„ íƒì )\n",
                "    clean_df = data_df[~data_df['collision']].copy()\n",
                "    print(f\"ì¶©ëŒ ì œì™¸ í›„: {len(clean_df):,} í”„ë ˆì„\")\n",
                "    \n",
                "    # ì•¡ì…˜ í†µê³„\n",
                "    print(f\"\\nì•¡ì…˜ í†µê³„:\")\n",
                "    print(f\"  Steer: mean={clean_df['steer'].mean():.4f}, std={clean_df['steer'].std():.4f}\")\n",
                "    print(f\"  Throttle: mean={clean_df['throttle'].mean():.4f}, std={clean_df['throttle'].std():.4f}\")\n",
                "    print(f\"  Brake: mean={clean_df['brake'].mean():.4f}, std={clean_df['brake'].std():.4f}\")\n",
                "    \n",
                "    # ì•¡ì…˜ ë¶„í¬ ì‹œê°í™”\n",
                "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "    \n",
                "    axes[0].hist(clean_df['steer'], bins=50, alpha=0.7)\n",
                "    axes[0].set_xlabel('Steer')\n",
                "    axes[0].set_title('Steer Distribution')\n",
                "    axes[0].axvline(0, color='red', linestyle='--')\n",
                "    \n",
                "    axes[1].hist(clean_df['throttle'], bins=50, alpha=0.7, color='green')\n",
                "    axes[1].set_xlabel('Throttle')\n",
                "    axes[1].set_title('Throttle Distribution')\n",
                "    \n",
                "    axes[2].hist(clean_df['brake'], bins=50, alpha=0.7, color='red')\n",
                "    axes[2].set_xlabel('Brake')\n",
                "    axes[2].set_title('Brake Distribution')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    clean_df = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: CARLA ë°ì´í„°ì…‹ í´ë˜ìŠ¤\n",
                "\n",
                "class CARLABCDataset(Dataset):\n",
                "    \"\"\"\n",
                "    CARLA í–‰ë™ í´ë¡œë‹ ë°ì´í„°ì…‹\n",
                "    \n",
                "    ì…ë ¥: RGB ì´ë¯¸ì§€\n",
                "    ì¶œë ¥: [steer, throttle, brake]\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, dataframe, transform=None):\n",
                "        self.df = dataframe.reset_index(drop=True)\n",
                "        self.transform = transform or T.Compose([\n",
                "            T.ToPILImage(),\n",
                "            T.Resize((224, 224)),\n",
                "            T.ToTensor(),\n",
                "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "        ])\n",
                "        \n",
                "        print(f\"ë°ì´í„°ì…‹ í¬ê¸°: {len(self.df):,}\")\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.df)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        \n",
                "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
                "        image_path = row['image_path']\n",
                "        image = cv2.imread(image_path)\n",
                "        \n",
                "        if image is None:\n",
                "            # ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ì¸ë±ìŠ¤ ë°˜í™˜\n",
                "            return self.__getitem__((idx + 1) % len(self))\n",
                "        \n",
                "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        # ë³€í™˜ ì ìš©\n",
                "        image = self.transform(image)\n",
                "        \n",
                "        # ì•¡ì…˜ (ì •ë‹µ)\n",
                "        action = torch.tensor([\n",
                "            row['steer'],\n",
                "            row['throttle'],\n",
                "            row['brake']\n",
                "        ], dtype=torch.float32)\n",
                "        \n",
                "        return image, action\n",
                "\n",
                "print(\"âœ… CARLABCDataset ì •ì˜ ì™„ë£Œ\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: ì „ì²´ ëª¨ë¸ ì •ì˜ (Encoder + Policy Head)\n",
                "\n",
                "class DrivingPolicyModel(nn.Module):\n",
                "    \"\"\"\n",
                "    ììœ¨ì£¼í–‰ ì •ì±… ëª¨ë¸\n",
                "    \n",
                "    êµ¬ì¡°:\n",
                "    1. Vision Encoder (ì‚¬ì „í•™ìŠµëœ ResNet-50)\n",
                "    2. Policy Head (MLP)\n",
                "    \n",
                "    ì¶œë ¥: [steer, throttle, brake]\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, encoder_type='resnet50', pretrained_ssl_path=None, freeze_encoder=True):\n",
                "        super().__init__()\n",
                "        \n",
                "        # Vision Encoder\n",
                "        if encoder_type == 'resnet50':\n",
                "            self.encoder = models.resnet50(pretrained=True)\n",
                "            self.feature_dim = self.encoder.fc.in_features  # 2048\n",
                "            self.encoder.fc = nn.Identity()\n",
                "        elif encoder_type == 'resnet34':\n",
                "            self.encoder = models.resnet34(pretrained=True)\n",
                "            self.feature_dim = self.encoder.fc.in_features  # 512\n",
                "            self.encoder.fc = nn.Identity()\n",
                "        else:\n",
                "            raise ValueError(f\"Unknown encoder: {encoder_type}\")\n",
                "        \n",
                "        # SSL ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
                "        if pretrained_ssl_path and Path(pretrained_ssl_path).exists():\n",
                "            checkpoint = torch.load(pretrained_ssl_path, map_location='cpu')\n",
                "            if 'encoder_state_dict' in checkpoint:\n",
                "                self.encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
                "                print(f\"âœ… SSL ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ë¡œë“œ: {pretrained_ssl_path}\")\n",
                "            else:\n",
                "                print(\"âš ï¸ encoder_state_dictë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
                "        \n",
                "        # Encoder ë™ê²°\n",
                "        if freeze_encoder:\n",
                "            for param in self.encoder.parameters():\n",
                "                param.requires_grad = False\n",
                "            print(\"ğŸ”’ Encoder ë™ê²°ë¨\")\n",
                "        \n",
                "        # Policy Head\n",
                "        hidden_dims = model_config['policy_head']['hidden_dims']  # [512, 256]\n",
                "        dropout = model_config['policy_head']['dropout']  # 0.3\n",
                "        \n",
                "        self.policy_head = nn.Sequential(\n",
                "            nn.Linear(self.feature_dim, hidden_dims[0]),\n",
                "            nn.ReLU(inplace=True),\n",
                "            nn.Dropout(dropout),\n",
                "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
                "            nn.ReLU(inplace=True),\n",
                "            nn.Dropout(dropout),\n",
                "            nn.Linear(hidden_dims[1], 3)  # [steer, throttle, brake]\n",
                "        )\n",
                "        \n",
                "        # ì¶œë ¥ í™œì„±í™”\n",
                "        self.steer_activation = nn.Tanh()  # [-1, 1]\n",
                "        self.throttle_brake_activation = nn.Sigmoid()  # [0, 1]\n",
                "        \n",
                "        print(f\"ëª¨ë¸ ìƒì„±: encoder={encoder_type}, feature_dim={self.feature_dim}\")\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # Encoder\n",
                "        features = self.encoder(x)\n",
                "        \n",
                "        # Policy Head\n",
                "        raw_output = self.policy_head(features)\n",
                "        \n",
                "        # í™œì„±í™” í•¨ìˆ˜ ì ìš©\n",
                "        steer = self.steer_activation(raw_output[:, 0:1])\n",
                "        throttle = self.throttle_brake_activation(raw_output[:, 1:2])\n",
                "        brake = self.throttle_brake_activation(raw_output[:, 2:3])\n",
                "        \n",
                "        action = torch.cat([steer, throttle, brake], dim=1)\n",
                "        \n",
                "        return action\n",
                "    \n",
                "    def unfreeze_encoder(self):\n",
                "        \"\"\"Encoder ë™ê²° í•´ì œ (fine-tuningìš©)\"\"\"\n",
                "        for param in self.encoder.parameters():\n",
                "            param.requires_grad = True\n",
                "        print(\"ğŸ”“ Encoder ë™ê²° í•´ì œë¨\")\n",
                "\n",
                "print(\"âœ… DrivingPolicyModel ì •ì˜ ì™„ë£Œ\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: ì†ì‹¤ í•¨ìˆ˜ ì •ì˜\n",
                "\n",
                "class BCLoss(nn.Module):\n",
                "    \"\"\"\n",
                "    í–‰ë™ í´ë¡œë‹ ì†ì‹¤ í•¨ìˆ˜\n",
                "    \n",
                "    L = w_steer * MSE(steer) + w_throttle * MSE(throttle) + w_brake * MSE(brake)\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, steer_weight=1.0, throttle_weight=0.5, brake_weight=0.5):\n",
                "        super().__init__()\n",
                "        self.steer_weight = steer_weight\n",
                "        self.throttle_weight = throttle_weight\n",
                "        self.brake_weight = brake_weight\n",
                "        self.mse = nn.MSELoss()\n",
                "    \n",
                "    def forward(self, predicted, target):\n",
                "        \"\"\"\n",
                "        Args:\n",
                "            predicted: [batch, 3] - [steer, throttle, brake]\n",
                "            target: [batch, 3] - [steer, throttle, brake]\n",
                "        \"\"\"\n",
                "        steer_loss = self.mse(predicted[:, 0], target[:, 0])\n",
                "        throttle_loss = self.mse(predicted[:, 1], target[:, 1])\n",
                "        brake_loss = self.mse(predicted[:, 2], target[:, 2])\n",
                "        \n",
                "        total_loss = (\n",
                "            self.steer_weight * steer_loss +\n",
                "            self.throttle_weight * throttle_loss +\n",
                "            self.brake_weight * brake_loss\n",
                "        )\n",
                "        \n",
                "        return total_loss, {\n",
                "            'steer': steer_loss.item(),\n",
                "            'throttle': throttle_loss.item(),\n",
                "            'brake': brake_loss.item()\n",
                "        }\n",
                "\n",
                "print(\"âœ… BCLoss ì •ì˜ ì™„ë£Œ\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 8: í•™ìŠµ ì„¤ì •\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
                "BATCH_SIZE = BC_CONFIG['batch_size']  # 32\n",
                "LEARNING_RATE = BC_CONFIG['learning_rate']  # 0.0001\n",
                "EPOCHS = BC_CONFIG['epochs']  # 50\n",
                "FREEZE_ENCODER = BC_CONFIG['encoder_freeze']  # True\n",
                "UNFREEZE_EPOCH = BC_CONFIG['unfreeze_epoch']  # 20\n",
                "\n",
                "# Train/Val ë¶„í• \n",
                "if len(clean_df) > 0:\n",
                "    train_df, val_df = train_test_split(clean_df, test_size=0.2, random_state=42)\n",
                "    print(f\"Train: {len(train_df):,} | Val: {len(val_df):,}\")\n",
                "    \n",
                "    # ë°ì´í„°ì…‹ ìƒì„±\n",
                "    train_dataset = CARLABCDataset(train_df)\n",
                "    val_dataset = CARLABCDataset(val_df)\n",
                "    \n",
                "    train_loader = DataLoader(\n",
                "        train_dataset,\n",
                "        batch_size=BATCH_SIZE,\n",
                "        shuffle=True,\n",
                "        num_workers=4,\n",
                "        pin_memory=True\n",
                "    )\n",
                "    val_loader = DataLoader(\n",
                "        val_dataset,\n",
                "        batch_size=BATCH_SIZE,\n",
                "        shuffle=False,\n",
                "        num_workers=4,\n",
                "        pin_memory=True\n",
                "    )\n",
                "    \n",
                "    print(f\"\\nTrain batches: {len(train_loader)}\")\n",
                "    print(f\"Val batches: {len(val_loader)}\")\n",
                "else:\n",
                "    train_loader = None\n",
                "    val_loader = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 9: ëª¨ë¸, ì˜µí‹°ë§ˆì´ì € ìƒì„±\n",
                "\n",
                "# SSL ì‚¬ì „í•™ìŠµ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ\n",
                "ssl_checkpoint_path = PROJECT_ROOT / 'checkpoints' / 'ssl' / 'ssl_final_model.pth'\n",
                "\n",
                "# ëª¨ë¸ ìƒì„±\n",
                "model = DrivingPolicyModel(\n",
                "    encoder_type=model_config['encoder']['type'],\n",
                "    pretrained_ssl_path=str(ssl_checkpoint_path) if ssl_checkpoint_path.exists() else None,\n",
                "    freeze_encoder=FREEZE_ENCODER\n",
                ").to(device)\n",
                "\n",
                "# ì†ì‹¤ í•¨ìˆ˜\n",
                "loss_weights = BC_CONFIG['loss_weights']\n",
                "criterion = BCLoss(\n",
                "    steer_weight=loss_weights['steer'],\n",
                "    throttle_weight=loss_weights['throttle'],\n",
                "    brake_weight=loss_weights['brake']\n",
                ")\n",
                "\n",
                "# ì˜µí‹°ë§ˆì´ì € (Policy Headë§Œ í•™ìŠµ)\n",
                "optimizer = optim.AdamW(\n",
                "    filter(lambda p: p.requires_grad, model.parameters()),\n",
                "    lr=LEARNING_RATE,\n",
                "    weight_decay=BC_CONFIG['weight_decay']\n",
                ")\n",
                "\n",
                "# ìŠ¤ì¼€ì¤„ëŸ¬\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
                "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
                ")\n",
                "\n",
                "# Mixed Precision\n",
                "scaler = GradScaler()\n",
                "\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"\\ní•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,} / {total_params:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 10: í•™ìŠµ í•¨ìˆ˜\n",
                "\n",
                "def train_epoch(model, train_loader, criterion, optimizer, scaler, device):\n",
                "    \"\"\"í•œ ì—í­ í•™ìŠµ\"\"\"\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    loss_details = {'steer': 0, 'throttle': 0, 'brake': 0}\n",
                "    \n",
                "    pbar = tqdm(train_loader, desc=\"Training\")\n",
                "    for images, actions in pbar:\n",
                "        images = images.to(device)\n",
                "        actions = actions.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        with autocast():\n",
                "            predicted = model(images)\n",
                "            loss, details = criterion(predicted, actions)\n",
                "        \n",
                "        scaler.scale(loss).backward()\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        for key in loss_details:\n",
                "            loss_details[key] += details[key]\n",
                "        \n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    n_batches = len(train_loader)\n",
                "    return (\n",
                "        total_loss / n_batches,\n",
                "        {k: v / n_batches for k, v in loss_details.items()}\n",
                "    )\n",
                "\n",
                "def validate(model, val_loader, criterion, device):\n",
                "    \"\"\"ê²€ì¦\"\"\"\n",
                "    model.eval()\n",
                "    total_loss = 0\n",
                "    loss_details = {'steer': 0, 'throttle': 0, 'brake': 0}\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for images, actions in val_loader:\n",
                "            images = images.to(device)\n",
                "            actions = actions.to(device)\n",
                "            \n",
                "            predicted = model(images)\n",
                "            loss, details = criterion(predicted, actions)\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "            for key in loss_details:\n",
                "                loss_details[key] += details[key]\n",
                "    \n",
                "    n_batches = len(val_loader)\n",
                "    return (\n",
                "        total_loss / n_batches,\n",
                "        {k: v / n_batches for k, v in loss_details.items()}\n",
                "    )\n",
                "\n",
                "print(\"âœ… í•™ìŠµ/ê²€ì¦ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 11: í•™ìŠµ ì‹¤í–‰\n",
                "\n",
                "# í•™ìŠµ ê¸°ë¡\n",
                "history = {\n",
                "    'train_loss': [], 'val_loss': [],\n",
                "    'train_steer': [], 'val_steer': [],\n",
                "    'train_throttle': [], 'val_throttle': [],\n",
                "    'train_brake': [], 'val_brake': [],\n",
                "    'lr': []\n",
                "}\n",
                "\n",
                "# ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬\n",
                "checkpoint_dir = PROJECT_ROOT / 'checkpoints' / 'bc'\n",
                "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "best_val_loss = float('inf')\n",
                "patience_counter = 0\n",
                "\n",
                "if train_loader:\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(\"í–‰ë™ í´ë¡œë‹ í•™ìŠµ ì‹œì‘\")\n",
                "    print(f\"{'='*50}\")\n",
                "    \n",
                "    try:\n",
                "        for epoch in range(EPOCHS):\n",
                "            print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
                "            \n",
                "            # Encoder ë™ê²° í•´ì œ\n",
                "            if epoch == UNFREEZE_EPOCH and FREEZE_ENCODER:\n",
                "                model.unfreeze_encoder()\n",
                "                # ì˜µí‹°ë§ˆì´ì € ì¬ì„¤ì •\n",
                "                optimizer = optim.AdamW(\n",
                "                    model.parameters(),\n",
                "                    lr=LEARNING_RATE / 10,  # ë” ë‚®ì€ í•™ìŠµë¥ \n",
                "                    weight_decay=BC_CONFIG['weight_decay']\n",
                "                )\n",
                "            \n",
                "            # í•™ìŠµ\n",
                "            train_loss, train_details = train_epoch(\n",
                "                model, train_loader, criterion, optimizer, scaler, device\n",
                "            )\n",
                "            \n",
                "            # ê²€ì¦\n",
                "            val_loss, val_details = validate(\n",
                "                model, val_loader, criterion, device\n",
                "            )\n",
                "            \n",
                "            # ê¸°ë¡\n",
                "            history['train_loss'].append(train_loss)\n",
                "            history['val_loss'].append(val_loss)\n",
                "            history['train_steer'].append(train_details['steer'])\n",
                "            history['val_steer'].append(val_details['steer'])\n",
                "            history['train_throttle'].append(train_details['throttle'])\n",
                "            history['val_throttle'].append(val_details['throttle'])\n",
                "            history['train_brake'].append(train_details['brake'])\n",
                "            history['val_brake'].append(val_details['brake'])\n",
                "            history['lr'].append(optimizer.param_groups[0]['lr'])\n",
                "            \n",
                "            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
                "            scheduler.step(val_loss)\n",
                "            \n",
                "            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
                "            print(f\"  Steer: T={train_details['steer']:.4f}, V={val_details['steer']:.4f}\")\n",
                "            print(f\"  Throttle: T={train_details['throttle']:.4f}, V={val_details['throttle']:.4f}\")\n",
                "            print(f\"  Brake: T={train_details['brake']:.4f}, V={val_details['brake']:.4f}\")\n",
                "            \n",
                "            # Best ëª¨ë¸ ì €ì¥\n",
                "            if val_loss < best_val_loss:\n",
                "                best_val_loss = val_loss\n",
                "                patience_counter = 0\n",
                "                torch.save({\n",
                "                    'epoch': epoch,\n",
                "                    'model_state_dict': model.state_dict(),\n",
                "                    'optimizer_state_dict': optimizer.state_dict(),\n",
                "                    'val_loss': val_loss,\n",
                "                }, checkpoint_dir / 'best_bc_model.pth')\n",
                "                print(\"â­ Best model saved!\")\n",
                "            else:\n",
                "                patience_counter += 1\n",
                "                if patience_counter >= BC_CONFIG['patience']:\n",
                "                    print(f\"\\nâš ï¸ Early stopping at epoch {epoch + 1}\")\n",
                "                    break\n",
                "    \n",
                "    except KeyboardInterrupt:\n",
                "        print(\"\\n\\nâš ï¸ í•™ìŠµ ì¤‘ë‹¨ë¨\")\n",
                "    \n",
                "    print(f\"\\ní•™ìŠµ ì™„ë£Œ! Best Val Loss: {best_val_loss:.4f}\")\n",
                "else:\n",
                "    print(\"âš ï¸ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 12: í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
                "\n",
                "if history['train_loss']:\n",
                "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "    \n",
                "    # Total Loss\n",
                "    axes[0, 0].plot(history['train_loss'], label='Train')\n",
                "    axes[0, 0].plot(history['val_loss'], label='Val')\n",
                "    axes[0, 0].set_xlabel('Epoch')\n",
                "    axes[0, 0].set_ylabel('Loss')\n",
                "    axes[0, 0].set_title('Total Loss')\n",
                "    axes[0, 0].legend()\n",
                "    axes[0, 0].grid(True, alpha=0.3)\n",
                "    \n",
                "    # Steer Loss\n",
                "    axes[0, 1].plot(history['train_steer'], label='Train')\n",
                "    axes[0, 1].plot(history['val_steer'], label='Val')\n",
                "    axes[0, 1].set_xlabel('Epoch')\n",
                "    axes[0, 1].set_ylabel('Loss')\n",
                "    axes[0, 1].set_title('Steer Loss')\n",
                "    axes[0, 1].legend()\n",
                "    axes[0, 1].grid(True, alpha=0.3)\n",
                "    \n",
                "    # Throttle Loss\n",
                "    axes[1, 0].plot(history['train_throttle'], label='Train')\n",
                "    axes[1, 0].plot(history['val_throttle'], label='Val')\n",
                "    axes[1, 0].set_xlabel('Epoch')\n",
                "    axes[1, 0].set_ylabel('Loss')\n",
                "    axes[1, 0].set_title('Throttle Loss')\n",
                "    axes[1, 0].legend()\n",
                "    axes[1, 0].grid(True, alpha=0.3)\n",
                "    \n",
                "    # Brake Loss\n",
                "    axes[1, 1].plot(history['train_brake'], label='Train')\n",
                "    axes[1, 1].plot(history['val_brake'], label='Val')\n",
                "    axes[1, 1].set_xlabel('Epoch')\n",
                "    axes[1, 1].set_ylabel('Loss')\n",
                "    axes[1, 1].set_title('Brake Loss')\n",
                "    axes[1, 1].legend()\n",
                "    axes[1, 1].grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(checkpoint_dir / 'training_curves.png', dpi=150)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 13: ê²€ì¦ ì„¸íŠ¸ ì˜ˆì¸¡ ì‹œê°í™”\n",
                "\n",
                "if val_loader and len(history['train_loss']) > 0:\n",
                "    model.eval()\n",
                "    \n",
                "    # ìƒ˜í”Œ ì˜ˆì¸¡\n",
                "    images, true_actions = next(iter(val_loader))\n",
                "    images = images.to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        pred_actions = model(images).cpu().numpy()\n",
                "    \n",
                "    true_actions = true_actions.numpy()\n",
                "    \n",
                "    # ì˜ˆì¸¡ vs ì‹¤ì œ ë¹„êµ\n",
                "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "    \n",
                "    # Steer\n",
                "    axes[0].scatter(true_actions[:, 0], pred_actions[:, 0], alpha=0.5)\n",
                "    axes[0].plot([-1, 1], [-1, 1], 'r--', label='y=x')\n",
                "    axes[0].set_xlabel('True Steer')\n",
                "    axes[0].set_ylabel('Predicted Steer')\n",
                "    axes[0].set_title('Steer: True vs Predicted')\n",
                "    axes[0].legend()\n",
                "    \n",
                "    # Throttle\n",
                "    axes[1].scatter(true_actions[:, 1], pred_actions[:, 1], alpha=0.5, color='green')\n",
                "    axes[1].plot([0, 1], [0, 1], 'r--', label='y=x')\n",
                "    axes[1].set_xlabel('True Throttle')\n",
                "    axes[1].set_ylabel('Predicted Throttle')\n",
                "    axes[1].set_title('Throttle: True vs Predicted')\n",
                "    axes[1].legend()\n",
                "    \n",
                "    # Brake\n",
                "    axes[2].scatter(true_actions[:, 2], pred_actions[:, 2], alpha=0.5, color='red')\n",
                "    axes[2].plot([0, 1], [0, 1], 'r--', label='y=x')\n",
                "    axes[2].set_xlabel('True Brake')\n",
                "    axes[2].set_ylabel('Predicted Brake')\n",
                "    axes[2].set_title('Brake: True vs Predicted')\n",
                "    axes[2].legend()\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(checkpoint_dir / 'prediction_comparison.png', dpi=150)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 14: ìµœì¢… ëª¨ë¸ ì €ì¥\n",
                "\n",
                "if len(history['train_loss']) > 0:\n",
                "    final_checkpoint = {\n",
                "        'model_state_dict': model.state_dict(),\n",
                "        'config': {\n",
                "            'encoder_type': model_config['encoder']['type'],\n",
                "            'feature_dim': model.feature_dim,\n",
                "            'policy_hidden': model_config['policy_head']['hidden_dims']\n",
                "        },\n",
                "        'training_config': BC_CONFIG,\n",
                "        'history': history,\n",
                "        'best_val_loss': best_val_loss,\n",
                "        'timestamp': datetime.now().isoformat()\n",
                "    }\n",
                "    \n",
                "    torch.save(final_checkpoint, checkpoint_dir / 'bc_final_model.pth')\n",
                "    print(f\"âœ… ìµœì¢… ëª¨ë¸ ì €ì¥: {checkpoint_dir / 'bc_final_model.pth'}\")\n",
                "\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(\"í–‰ë™ í´ë¡œë‹ í•™ìŠµ ì™„ë£Œ\")\n",
                "print(f\"{'='*50}\")\n",
                "print(f\"ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬: {checkpoint_dir}\")\n",
                "print(f\"\\në‹¤ìŒ ë‹¨ê³„: 06_safety_shield.ipynb\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## í–‰ë™ í´ë¡œë‹ ìš”ì•½\n",
                "\n",
                "### ëª¨ë¸ êµ¬ì¡°\n",
                "- **Vision Encoder**: ResNet-50 (KITTI Self-supervised ì‚¬ì „í•™ìŠµ)\n",
                "- **Policy Head**: MLP [2048 â†’ 512 â†’ 256 â†’ 3]\n",
                "- **ì¶œë ¥**: [steer, throttle, brake]\n",
                "\n",
                "### í•™ìŠµ ì „ëµ\n",
                "1. ì´ˆê¸°: Encoder ë™ê²°, Policy Headë§Œ í•™ìŠµ\n",
                "2. í›„ê¸°: Encoder ë™ê²° í•´ì œ, ì „ì²´ fine-tuning\n",
                "\n",
                "### ì°¸ê³  ë…¼ë¬¸\n",
                "\n",
                "| ë…¼ë¬¸ | í•µì‹¬ ì•„ì´ë””ì–´ |\n",
                "|------|---------------|\n",
                "| ALVINN (Pomerleau, 1988) | ìµœì´ˆì˜ neural network ììœ¨ì£¼í–‰, ì´ë¯¸ì§€â†’ì¡°í–¥ ì§ì ‘ í•™ìŠµ |\n",
                "| PilotNet (Bojarski et al., 2016) | NVIDIAì˜ End-to-end ììœ¨ì£¼í–‰, CNN ê¸°ë°˜ |\n",
                "| DAgger (Ross et al., 2011) | Distribution shift ë¬¸ì œ í•´ê²°, ì˜¨ë¼ì¸ í•™ìŠµ |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}