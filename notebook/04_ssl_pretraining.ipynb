{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cell 1: 노트북 개요\n",
                "\n",
                "## 04_ssl_pretraining.ipynb - Self-supervised 사전학습\n",
                "\n",
                "이 노트북에서는 KITTI 데이터로 SimCLR 기반 Self-supervised 학습을 수행합니다.\n",
                "\n",
                "### 목표\n",
                "1. SimCLR 아키텍처 구현\n",
                "2. Contrastive Loss (NT-Xent) 구현\n",
                "3. KITTI 데이터로 사전학습\n",
                "4. 학습된 표현 품질 평가\n",
                "\n",
                "### 참고 논문\n",
                "- **SimCLR** (Chen et al., ICML 2020): A Simple Framework for Contrastive Learning of Visual Representations\n",
                "- **NT-Xent Loss**: Normalized Temperature-scaled Cross Entropy Loss\n",
                "\n",
                "### GPU 최적화 (GTX 1080Ti 11GB)\n",
                "- Batch size: 16\n",
                "- Mixed Precision (FP16)\n",
                "- ResNet-50 backbone"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: 라이브러리 및 설정\n",
                "\n",
                "import sys\n",
                "import os\n",
                "import json\n",
                "import logging\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "from tqdm.notebook import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torch.cuda.amp import autocast, GradScaler\n",
                "import torchvision.transforms as T\n",
                "import torchvision.models as models\n",
                "\n",
                "# 프로젝트 루트\n",
                "PROJECT_ROOT = Path().absolute().parent\n",
                "sys.path.insert(0, str(PROJECT_ROOT))\n",
                "\n",
                "# 로깅 설정\n",
                "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "# GPU 확인\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Device: {device}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: 학습 설정 로드\n",
                "\n",
                "import yaml\n",
                "\n",
                "# 설정 파일 로드\n",
                "training_config_path = PROJECT_ROOT / 'config' / 'training_config.yaml'\n",
                "with open(training_config_path, 'r', encoding='utf-8') as f:\n",
                "    training_config = yaml.safe_load(f)\n",
                "\n",
                "model_config_path = PROJECT_ROOT / 'config' / 'model_config.yaml'\n",
                "with open(model_config_path, 'r', encoding='utf-8') as f:\n",
                "    model_config = yaml.safe_load(f)\n",
                "\n",
                "# SSL 학습 설정\n",
                "SSL_CONFIG = training_config['ssl_training']\n",
                "print(\"Self-supervised 학습 설정:\")\n",
                "for key, value in SSL_CONFIG.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: KITTI 데이터셋 로드\n",
                "\n",
                "import cv2\n",
                "\n",
                "# 데이터셋 정보 로드\n",
                "dataset_info_path = PROJECT_ROOT / 'dataset' / 'kitti_dataset_info.json'\n",
                "\n",
                "if dataset_info_path.exists():\n",
                "    with open(dataset_info_path, 'r') as f:\n",
                "        kitti_info = json.load(f)\n",
                "    print(f\"KITTI 시퀀스: {kitti_info['total_sequences']}개\")\n",
                "    print(f\"Train 시퀀스: {kitti_info['train_sequences']}개\")\n",
                "    print(f\"Val 시퀀스: {kitti_info['val_sequences']}개\")\n",
                "else:\n",
                "    print(\"⚠️ kitti_dataset_info.json이 없습니다.\")\n",
                "    print(\"03_kitti_exploration.ipynb를 먼저 실행해주세요.\")\n",
                "    kitti_info = {'train_paths': [], 'val_paths': []}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: SimCLR 데이터 증강 파이프라인\n",
                "\n",
                "class SimCLRAugmentation:\n",
                "    \"\"\"\n",
                "    SimCLR 스타일 데이터 증강\n",
                "    \n",
                "    논문: Chen et al., \"A Simple Framework for Contrastive Learning\" (ICML 2020)\n",
                "    핵심: 강력한 augmentation이 contrastive learning 성능의 핵심\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, size=224):\n",
                "        self.transform = T.Compose([\n",
                "            T.ToPILImage(),\n",
                "            T.RandomResizedCrop(size, scale=(0.2, 1.0)),\n",
                "            T.RandomHorizontalFlip(p=0.5),\n",
                "            T.RandomApply([\n",
                "                T.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
                "            ], p=0.8),\n",
                "            T.RandomGrayscale(p=0.2),\n",
                "            T.RandomApply([\n",
                "                T.GaussianBlur(kernel_size=23)\n",
                "            ], p=0.5),\n",
                "            T.ToTensor(),\n",
                "            T.Normalize(mean=[0.485, 0.456, 0.406], \n",
                "                        std=[0.229, 0.224, 0.225])\n",
                "        ])\n",
                "    \n",
                "    def __call__(self, x):\n",
                "        return self.transform(x), self.transform(x)\n",
                "\n",
                "print(\"✅ SimCLRAugmentation 정의 완료\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: KITTI 데이터셋 클래스\n",
                "\n",
                "class KITTIContrastiveDataset(Dataset):\n",
                "    \"\"\"\n",
                "    KITTI Contrastive Learning 데이터셋\n",
                "    \n",
                "    각 이미지에 두 가지 다른 augmentation을 적용하여\n",
                "    positive pair를 생성\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, sequence_paths, augmentation=None, max_samples=None):\n",
                "        self.augmentation = augmentation or SimCLRAugmentation()\n",
                "        self.image_paths = []\n",
                "        \n",
                "        # 모든 이미지 경로 수집\n",
                "        for seq_path in sequence_paths:\n",
                "            seq_dir = Path(seq_path)\n",
                "            if seq_dir.exists():\n",
                "                images = list(seq_dir.glob('*.png')) + list(seq_dir.glob('*.jpg'))\n",
                "                self.image_paths.extend([str(p) for p in images])\n",
                "        \n",
                "        # 최대 샘플 수 제한 (메모리 관리)\n",
                "        if max_samples and len(self.image_paths) > max_samples:\n",
                "            np.random.shuffle(self.image_paths)\n",
                "            self.image_paths = self.image_paths[:max_samples]\n",
                "        \n",
                "        print(f\"데이터셋 크기: {len(self.image_paths):,}\")\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.image_paths)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        # 이미지 로드\n",
                "        img = cv2.imread(self.image_paths[idx])\n",
                "        if img is None:\n",
                "            # 로드 실패 시 다른 이미지 반환\n",
                "            return self.__getitem__((idx + 1) % len(self))\n",
                "        \n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        # 두 가지 증강 적용\n",
                "        x1, x2 = self.augmentation(img)\n",
                "        \n",
                "        return x1, x2\n",
                "\n",
                "print(\"✅ KITTIContrastiveDataset 정의 완료\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: SimCLR 모델 정의\n",
                "\n",
                "class SimCLR(nn.Module):\n",
                "    \"\"\"\n",
                "    SimCLR 모델\n",
                "    \n",
                "    구조:\n",
                "    1. Encoder (ResNet-50): 이미지 → 특징 벡터\n",
                "    2. Projection Head: 특징 → contrastive space로 매핑\n",
                "    \n",
                "    논문: Chen et al., ICML 2020\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, base_encoder='resnet50', projection_dim=128):\n",
                "        super().__init__()\n",
                "        \n",
                "        # Backbone encoder\n",
                "        if base_encoder == 'resnet50':\n",
                "            self.encoder = models.resnet50(pretrained=True)\n",
                "            self.feature_dim = self.encoder.fc.in_features  # 2048\n",
                "            self.encoder.fc = nn.Identity()  # FC 레이어 제거\n",
                "        elif base_encoder == 'resnet34':\n",
                "            self.encoder = models.resnet34(pretrained=True)\n",
                "            self.feature_dim = self.encoder.fc.in_features  # 512\n",
                "            self.encoder.fc = nn.Identity()\n",
                "        else:\n",
                "            raise ValueError(f\"Unknown encoder: {base_encoder}\")\n",
                "        \n",
                "        # Projection head (MLP)\n",
                "        self.projection_head = nn.Sequential(\n",
                "            nn.Linear(self.feature_dim, self.feature_dim),\n",
                "            nn.ReLU(inplace=True),\n",
                "            nn.Linear(self.feature_dim, projection_dim)\n",
                "        )\n",
                "        \n",
                "        print(f\"SimCLR 모델 생성: {base_encoder}, feature_dim={self.feature_dim}\")\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # Encoder로 특징 추출\n",
                "        h = self.encoder(x)\n",
                "        \n",
                "        # Projection head로 매핑\n",
                "        z = self.projection_head(h)\n",
                "        \n",
                "        return h, z\n",
                "    \n",
                "    def get_encoder(self):\n",
                "        \"\"\"학습된 encoder 반환 (downstream task용)\"\"\"\n",
                "        return self.encoder\n",
                "\n",
                "print(\"✅ SimCLR 모델 정의 완료\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: NT-Xent Loss (Contrastive Loss)\n",
                "\n",
                "class NTXentLoss(nn.Module):\n",
                "    \"\"\"\n",
                "    Normalized Temperature-scaled Cross Entropy Loss\n",
                "    \n",
                "    같은 이미지의 두 augmentation은 가깝게,\n",
                "    다른 이미지는 멀게 학습\n",
                "    \n",
                "    수식: L = -log(exp(sim(z_i, z_j)/τ) / Σ exp(sim(z_i, z_k)/τ))\n",
                "    \n",
                "    논문: Chen et al., ICML 2020\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, temperature=0.5):\n",
                "        super().__init__()\n",
                "        self.temperature = temperature\n",
                "    \n",
                "    def forward(self, z1, z2):\n",
                "        \"\"\"\n",
                "        Args:\n",
                "            z1, z2: projection outputs (batch_size, projection_dim)\n",
                "        \"\"\"\n",
                "        batch_size = z1.shape[0]\n",
                "        \n",
                "        # L2 정규화\n",
                "        z1 = F.normalize(z1, dim=1)\n",
                "        z2 = F.normalize(z2, dim=1)\n",
                "        \n",
                "        # 모든 쌍에 대한 유사도 계산\n",
                "        representations = torch.cat([z1, z2], dim=0)  # (2*batch_size, dim)\n",
                "        similarity_matrix = torch.mm(representations, representations.T)  # (2N, 2N)\n",
                "        \n",
                "        # 자기 자신과의 유사도는 제외\n",
                "        mask = torch.eye(2 * batch_size, device=z1.device).bool()\n",
                "        similarity_matrix = similarity_matrix.masked_fill(mask, -float('inf'))\n",
                "        \n",
                "        # Positive pairs의 인덱스\n",
                "        # z1[i]와 z2[i]는 positive pair\n",
                "        positives = torch.cat([\n",
                "            torch.diag(similarity_matrix[:batch_size, batch_size:]),  # z1 <-> z2\n",
                "            torch.diag(similarity_matrix[batch_size:, :batch_size])   # z2 <-> z1\n",
                "        ])\n",
                "        \n",
                "        # 온도 스케일링\n",
                "        similarity_matrix = similarity_matrix / self.temperature\n",
                "        positives = positives / self.temperature\n",
                "        \n",
                "        # Contrastive loss 계산\n",
                "        # 각 샘플에 대해 positive를 찾는 cross entropy\n",
                "        logits = torch.cat([\n",
                "            positives.unsqueeze(1),\n",
                "            similarity_matrix.view(2 * batch_size, -1)\n",
                "        ], dim=1)\n",
                "        \n",
                "        labels = torch.zeros(2 * batch_size, dtype=torch.long, device=z1.device)\n",
                "        \n",
                "        loss = F.cross_entropy(logits, labels)\n",
                "        \n",
                "        return loss\n",
                "\n",
                "print(\"✅ NTXentLoss 정의 완료\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 8: 학습 설정\n",
                "\n",
                "# 하이퍼파라미터\n",
                "BATCH_SIZE = SSL_CONFIG['batch_size']  # 16\n",
                "LEARNING_RATE = SSL_CONFIG['learning_rate']  # 0.001\n",
                "EPOCHS = SSL_CONFIG['epochs']  # 100\n",
                "TEMPERATURE = SSL_CONFIG['temperature']  # 0.5\n",
                "USE_AMP = SSL_CONFIG['mixed_precision']  # True\n",
                "\n",
                "# 데이터셋 생성\n",
                "train_paths = kitti_info.get('train_paths', [])\n",
                "val_paths = kitti_info.get('val_paths', [])\n",
                "\n",
                "# 메모리 관리를 위해 샘플 수 제한\n",
                "MAX_TRAIN_SAMPLES = 10000  # 실제 학습 시 None으로 설정\n",
                "MAX_VAL_SAMPLES = 2000\n",
                "\n",
                "if train_paths:\n",
                "    train_dataset = KITTIContrastiveDataset(\n",
                "        train_paths, \n",
                "        augmentation=SimCLRAugmentation(224),\n",
                "        max_samples=MAX_TRAIN_SAMPLES\n",
                "    )\n",
                "    train_loader = DataLoader(\n",
                "        train_dataset, \n",
                "        batch_size=BATCH_SIZE, \n",
                "        shuffle=True,\n",
                "        num_workers=4,\n",
                "        pin_memory=True,\n",
                "        drop_last=True\n",
                "    )\n",
                "    print(f\"Train DataLoader: {len(train_loader)} batches\")\n",
                "else:\n",
                "    print(\"⚠️ Train 데이터가 없습니다.\")\n",
                "    train_loader = None\n",
                "\n",
                "if val_paths:\n",
                "    val_dataset = KITTIContrastiveDataset(\n",
                "        val_paths,\n",
                "        augmentation=SimCLRAugmentation(224),\n",
                "        max_samples=MAX_VAL_SAMPLES\n",
                "    )\n",
                "    val_loader = DataLoader(\n",
                "        val_dataset,\n",
                "        batch_size=BATCH_SIZE,\n",
                "        shuffle=False,\n",
                "        num_workers=4,\n",
                "        pin_memory=True\n",
                "    )\n",
                "    print(f\"Val DataLoader: {len(val_loader)} batches\")\n",
                "else:\n",
                "    val_loader = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 9: 모델, 옵티마이저, 스케줄러 생성\n",
                "\n",
                "# 모델\n",
                "model = SimCLR(\n",
                "    base_encoder=model_config['encoder']['type'],  # resnet50\n",
                "    projection_dim=128\n",
                ").to(device)\n",
                "\n",
                "# 손실 함수\n",
                "criterion = NTXentLoss(temperature=TEMPERATURE)\n",
                "\n",
                "# 옵티마이저\n",
                "optimizer = optim.AdamW(\n",
                "    model.parameters(),\n",
                "    lr=LEARNING_RATE,\n",
                "    weight_decay=SSL_CONFIG['weight_decay']\n",
                ")\n",
                "\n",
                "# 스케줄러 (Cosine Annealing)\n",
                "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
                "    optimizer,\n",
                "    T_max=EPOCHS,\n",
                "    eta_min=1e-6\n",
                ")\n",
                "\n",
                "# Mixed Precision\n",
                "scaler = GradScaler() if USE_AMP else None\n",
                "\n",
                "print(f\"\\n모델 파라미터 수: {sum(p.numel() for p in model.parameters()):,}\")\n",
                "print(f\"학습 가능 파라미터: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 10: 학습 함수\n",
                "\n",
                "def train_epoch(model, train_loader, criterion, optimizer, scaler, device):\n",
                "    \"\"\"한 에폭 학습\"\"\"\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    \n",
                "    pbar = tqdm(train_loader, desc=\"Training\")\n",
                "    for x1, x2 in pbar:\n",
                "        x1, x2 = x1.to(device), x2.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        if scaler:  # Mixed Precision\n",
                "            with autocast():\n",
                "                _, z1 = model(x1)\n",
                "                _, z2 = model(x2)\n",
                "                loss = criterion(z1, z2)\n",
                "            \n",
                "            scaler.scale(loss).backward()\n",
                "            scaler.step(optimizer)\n",
                "            scaler.update()\n",
                "        else:\n",
                "            _, z1 = model(x1)\n",
                "            _, z2 = model(x2)\n",
                "            loss = criterion(z1, z2)\n",
                "            \n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    return total_loss / len(train_loader)\n",
                "\n",
                "def validate(model, val_loader, criterion, device):\n",
                "    \"\"\"검증\"\"\"\n",
                "    model.eval()\n",
                "    total_loss = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for x1, x2 in val_loader:\n",
                "            x1, x2 = x1.to(device), x2.to(device)\n",
                "            \n",
                "            _, z1 = model(x1)\n",
                "            _, z2 = model(x2)\n",
                "            loss = criterion(z1, z2)\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "    \n",
                "    return total_loss / len(val_loader)\n",
                "\n",
                "print(\"✅ 학습/검증 함수 정의 완료\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 11: 학습 실행\n",
                "\n",
                "# 학습 기록\n",
                "history = {\n",
                "    'train_loss': [],\n",
                "    'val_loss': [],\n",
                "    'lr': []\n",
                "}\n",
                "\n",
                "# 체크포인트 디렉토리\n",
                "checkpoint_dir = PROJECT_ROOT / 'checkpoints' / 'ssl'\n",
                "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "best_val_loss = float('inf')\n",
                "\n",
                "if train_loader:\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"Self-supervised 학습 시작\")\n",
                "    print(f\"{'='*50}\")\n",
                "    print(f\"Epochs: {EPOCHS}\")\n",
                "    print(f\"Batch size: {BATCH_SIZE}\")\n",
                "    print(f\"Learning rate: {LEARNING_RATE}\")\n",
                "    print(f\"Temperature: {TEMPERATURE}\")\n",
                "    print(f\"Mixed Precision: {USE_AMP}\")\n",
                "    print(f\"{'='*50}\\n\")\n",
                "    \n",
                "    try:\n",
                "        for epoch in range(EPOCHS):\n",
                "            print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
                "            \n",
                "            # 학습\n",
                "            train_loss = train_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
                "            history['train_loss'].append(train_loss)\n",
                "            \n",
                "            # 검증\n",
                "            if val_loader:\n",
                "                val_loss = validate(model, val_loader, criterion, device)\n",
                "                history['val_loss'].append(val_loss)\n",
                "            else:\n",
                "                val_loss = train_loss\n",
                "                history['val_loss'].append(val_loss)\n",
                "            \n",
                "            # 학습률 기록\n",
                "            current_lr = optimizer.param_groups[0]['lr']\n",
                "            history['lr'].append(current_lr)\n",
                "            \n",
                "            # 스케줄러 업데이트\n",
                "            scheduler.step()\n",
                "            \n",
                "            print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | LR: {current_lr:.6f}\")\n",
                "            \n",
                "            # Best 모델 저장\n",
                "            if val_loss < best_val_loss:\n",
                "                best_val_loss = val_loss\n",
                "                torch.save({\n",
                "                    'epoch': epoch,\n",
                "                    'model_state_dict': model.state_dict(),\n",
                "                    'optimizer_state_dict': optimizer.state_dict(),\n",
                "                    'val_loss': val_loss,\n",
                "                }, checkpoint_dir / 'best_ssl_model.pth')\n",
                "                print(f\"⭐ Best model saved!\")\n",
                "            \n",
                "            # 주기적 저장\n",
                "            if (epoch + 1) % 10 == 0:\n",
                "                torch.save({\n",
                "                    'epoch': epoch,\n",
                "                    'model_state_dict': model.state_dict(),\n",
                "                    'optimizer_state_dict': optimizer.state_dict(),\n",
                "                    'val_loss': val_loss,\n",
                "                }, checkpoint_dir / f'ssl_model_epoch_{epoch+1}.pth')\n",
                "    \n",
                "    except KeyboardInterrupt:\n",
                "        print(\"\\n\\n⚠️ 학습 중단됨\")\n",
                "    \n",
                "    print(f\"\\n학습 완료! Best Val Loss: {best_val_loss:.4f}\")\n",
                "else:\n",
                "    print(\"⚠️ 학습 데이터가 없어 학습을 실행할 수 없습니다.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 12: 학습 곡선 시각화\n",
                "\n",
                "if history['train_loss']:\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "    \n",
                "    # Loss\n",
                "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
                "    axes[0].plot(history['val_loss'], label='Val Loss')\n",
                "    axes[0].set_xlabel('Epoch')\n",
                "    axes[0].set_ylabel('Loss')\n",
                "    axes[0].set_title('Training and Validation Loss')\n",
                "    axes[0].legend()\n",
                "    axes[0].grid(True, alpha=0.3)\n",
                "    \n",
                "    # Learning Rate\n",
                "    axes[1].plot(history['lr'])\n",
                "    axes[1].set_xlabel('Epoch')\n",
                "    axes[1].set_ylabel('Learning Rate')\n",
                "    axes[1].set_title('Learning Rate Schedule (Cosine Annealing)')\n",
                "    axes[1].grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(checkpoint_dir / 'training_curves.png', dpi=150)\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"학습 기록이 없습니다.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 13: 학습된 표현 품질 평가 (t-SNE)\n",
                "\n",
                "from sklearn.manifold import TSNE\n",
                "\n",
                "def extract_features(model, dataloader, device, max_samples=1000):\n",
                "    \"\"\"특징 벡터 추출\"\"\"\n",
                "    model.eval()\n",
                "    features = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for x1, x2 in dataloader:\n",
                "            x1 = x1.to(device)\n",
                "            h, _ = model(x1)\n",
                "            features.append(h.cpu().numpy())\n",
                "            \n",
                "            if len(features) * x1.shape[0] >= max_samples:\n",
                "                break\n",
                "    \n",
                "    return np.vstack(features)[:max_samples]\n",
                "\n",
                "if train_loader and len(history['train_loss']) > 0:\n",
                "    print(\"특징 추출 중...\")\n",
                "    features = extract_features(model, train_loader, device, max_samples=500)\n",
                "    \n",
                "    print(f\"t-SNE 계산 중... (features shape: {features.shape})\")\n",
                "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
                "    embeddings = tsne.fit_transform(features)\n",
                "    \n",
                "    plt.figure(figsize=(10, 8))\n",
                "    plt.scatter(embeddings[:, 0], embeddings[:, 1], alpha=0.5, s=10)\n",
                "    plt.xlabel('t-SNE 1')\n",
                "    plt.ylabel('t-SNE 2')\n",
                "    plt.title('t-SNE Visualization of Learned Representations')\n",
                "    plt.savefig(checkpoint_dir / 'tsne_visualization.png', dpi=150)\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"t-SNE 시각화를 위한 학습 데이터가 없습니다.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 14: 체크포인트 저장 및 요약\n",
                "\n",
                "# 최종 모델 저장\n",
                "if len(history['train_loss']) > 0:\n",
                "    final_checkpoint = {\n",
                "        'model_state_dict': model.state_dict(),\n",
                "        'encoder_state_dict': model.encoder.state_dict(),  # encoder만 따로 저장\n",
                "        'config': {\n",
                "            'base_encoder': model_config['encoder']['type'],\n",
                "            'feature_dim': model.feature_dim,\n",
                "            'projection_dim': 128\n",
                "        },\n",
                "        'training_config': SSL_CONFIG,\n",
                "        'history': history,\n",
                "        'best_val_loss': best_val_loss,\n",
                "        'timestamp': datetime.now().isoformat()\n",
                "    }\n",
                "    \n",
                "    torch.save(final_checkpoint, checkpoint_dir / 'ssl_final_model.pth')\n",
                "    print(f\"✅ 최종 모델 저장: {checkpoint_dir / 'ssl_final_model.pth'}\")\n",
                "\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(\"Self-supervised 사전학습 완료\")\n",
                "print(f\"{'='*50}\")\n",
                "print(f\"체크포인트 디렉토리: {checkpoint_dir}\")\n",
                "print(f\"Best Val Loss: {best_val_loss:.4f}\" if 'best_val_loss' in dir() else \"\")\n",
                "print(f\"\\n다음 단계: 05_bc_training.ipynb\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Self-supervised 학습 요약\n",
                "\n",
                "### 방법론: SimCLR\n",
                "- **Contrastive Learning**: 같은 이미지의 다른 augmentation은 가깝게, 다른 이미지는 멀게\n",
                "- **NT-Xent Loss**: Temperature-scaled cross entropy\n",
                "- **강력한 Augmentation**: ColorJitter, GaussianBlur, RandomCrop 등\n",
                "\n",
                "### 결과물\n",
                "- `checkpoints/ssl/best_ssl_model.pth`: Best validation loss 모델\n",
                "- `checkpoints/ssl/ssl_final_model.pth`: 최종 모델 (encoder 포함)\n",
                "\n",
                "### 참고 논문\n",
                "\n",
                "| 논문 | 핵심 아이디어 |\n",
                "|------|---------------|\n",
                "| SimCLR (Chen et al., 2020) | 강력한 augmentation + contrastive learning으로 라벨 없이 표현 학습 |\n",
                "| MoCo (He et al., 2020) | Momentum encoder로 큰 negative pool 유지 |\n",
                "| BYOL (Grill et al., 2020) | Negative sample 없이 자기 지도 학습 |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}