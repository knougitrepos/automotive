{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cell 1: ë…¸íŠ¸ë¶ ê°œìš”\n",
                "\n",
                "## 03_kitti_exploration.ipynb - KITTI ë°ì´í„° íƒìƒ‰\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” KITTI ë°ì´í„°ì…‹ì„ íƒìƒ‰í•˜ê³  Self-supervised ì‚¬ì „í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
                "\n",
                "### ëª©í‘œ\n",
                "1. KITTI ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸\n",
                "2. ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ë¡œë“œ ë° ì‹œê°í™”\n",
                "3. ì—°ì† í”„ë ˆì„ ë¶„ì„\n",
                "4. Self-supervised í•™ìŠµìš© ë°ì´í„°ì…‹ êµ¬ì„±\n",
                "5. Train/Val ë¶„í• \n",
                "\n",
                "### ì°¸ê³  ë…¼ë¬¸\n",
                "- **KITTI Vision Benchmark** (Geiger et al., CVPR 2012): ììœ¨ì£¼í–‰ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹\n",
                "- **SimCLR** (Chen et al., ICML 2020): Contrastive learningì„ ìœ„í•œ ì—°ì† í”„ë ˆì„ í™œìš©"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •\n",
                "\n",
                "import sys\n",
                "import os\n",
                "import glob\n",
                "import logging\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import cv2\n",
                "from pathlib import Path\n",
                "from collections import defaultdict\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "# í”„ë¡œì íŠ¸ ë£¨íŠ¸\n",
                "PROJECT_ROOT = Path().absolute().parent\n",
                "sys.path.insert(0, str(PROJECT_ROOT))\n",
                "\n",
                "# ë¡œê¹… ì„¤ì •\n",
                "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
                "logger = logging.getLogger(__name__)\n",
                "\n",
                "# KITTI ë°ì´í„° ê²½ë¡œ\n",
                "DATASET_ROOT = PROJECT_ROOT / 'dataset'\n",
                "KITTI_PATHS = {\n",
                "    'kitti_tracking': DATASET_ROOT / 'kitti_tracking',\n",
                "    # 'kitti_raw': DATASET_ROOT / 'kitti', # í•„ìš”ì‹œ ì¶”ê°€\n",
                "}\n",
                "\n",
                "print(f\"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}\")\n",
                "print(f\"ë°ì´í„°ì…‹ ë£¨íŠ¸: {DATASET_ROOT}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: KITTI ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸\n",
                "\n",
                "def explore_directory(path, max_depth=3, current_depth=0):\n",
                "    \"\"\"ë””ë ‰í† ë¦¬ êµ¬ì¡° íƒìƒ‰\"\"\"\n",
                "    if current_depth >= max_depth:\n",
                "        return\n",
                "    \n",
                "    path = Path(path)\n",
                "    if not path.exists():\n",
                "        print(f\"{'  ' * current_depth}âŒ {path.name} (ì—†ìŒ)\")\n",
                "        return\n",
                "    \n",
                "    indent = '  ' * current_depth\n",
                "    \n",
                "    if path.is_file():\n",
                "        size_mb = path.stat().st_size / (1024 * 1024)\n",
                "        print(f\"{indent}ğŸ“„ {path.name} ({size_mb:.1f} MB)\")\n",
                "    else:\n",
                "        children = list(path.iterdir())\n",
                "        print(f\"{indent}ğŸ“ {path.name}/ ({len(children)} items)\")\n",
                "        \n",
                "        # í•˜ìœ„ í•­ëª© (ìµœëŒ€ 5ê°œ)\n",
                "        for child in children[:5]:\n",
                "            explore_directory(child, max_depth, current_depth + 1)\n",
                "        \n",
                "        if len(children) > 5:\n",
                "            print(f\"{indent}  ... ê·¸ ì™¸ {len(children) - 5}ê°œ\")\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"KITTI ë°ì´í„°ì…‹ êµ¬ì¡° íƒìƒ‰\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "for name, path in KITTI_PATHS.items():\n",
                "    print(f\"\\n[{name}]\")\n",
                "    explore_directory(path, max_depth=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ ì°¾ê¸°\n",
                "\n",
                "from utils.data_utils import get_kitti_sequences\n",
                "\n",
                "# ëª¨ë“  ì‹œí€€ìŠ¤ ì°¾ê¸°\n",
                "all_sequences = []\n",
                "for name, path in KITTI_PATHS.items():\n",
                "    print(f\"ê²€ìƒ‰ ê²½ë¡œ: {path}\")\n",
                "    seqs = get_kitti_sequences(str(path))\n",
                "    all_sequences.extend(seqs)\n",
                "    print(f\"{name}: {len(seqs)}ê°œ ì‹œí€€ìŠ¤ ë°œê²¬\")\n",
                "\n",
                "# ì¤‘ë³µ ì œê±°\n",
                "all_sequences = sorted(list(set(all_sequences)))\n",
                "print(f\"\\nì´ {len(all_sequences)}ê°œ ê³ ìœ  ì‹œí€€ìŠ¤ ë°œê²¬\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: ì‹œí€€ìŠ¤ ì •ë³´ ë¶„ì„\n",
                "\n",
                "sequence_info = []\n",
                "\n",
                "for seq_dir in tqdm(all_sequences, desc=\"ì‹œí€€ìŠ¤ ë¶„ì„\"):\n",
                "    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°\n",
                "    seq_path = Path(seq_dir)\n",
                "    images = sorted(list(seq_path.glob('*.png')) + list(seq_path.glob('*.jpg')))\n",
                "    \n",
                "    if len(images) == 0:\n",
                "        continue\n",
                "    \n",
                "    # ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ í¬ê¸° í™•ì¸\n",
                "    sample_img = cv2.imread(str(images[0]))\n",
                "    if sample_img is None:\n",
                "        continue\n",
                "    \n",
                "    height, width = sample_img.shape[:2]\n",
                "    \n",
                "    sequence_info.append({\n",
                "        'path': str(seq_dir),\n",
                "        'num_images': len(images),\n",
                "        'width': width,\n",
                "        'height': height,\n",
                "        'extension': images[0].suffix\n",
                "    })\n",
                "\n",
                "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
                "seq_df = pd.DataFrame(sequence_info)\n",
                "\n",
                "if len(seq_df) > 0:\n",
                "    print(f\"\\nì´ ì‹œí€€ìŠ¤: {len(seq_df)}ê°œ\")\n",
                "    print(f\"ì´ ì´ë¯¸ì§€: {seq_df['num_images'].sum():,}ì¥\")\n",
                "    print(f\"\\nì´ë¯¸ì§€ í¬ê¸° ë¶„í¬:\")\n",
                "    print(seq_df.groupby(['width', 'height']).size())\n",
                "    print(f\"\\nì‹œí€€ìŠ¤ ê¸¸ì´ í†µê³„:\")\n",
                "    print(seq_df['num_images'].describe())\n",
                "else:\n",
                "    print(\"ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: ìƒ˜í”Œ ì‹œí€€ìŠ¤ ì‹œê°í™”\n",
                "\n",
                "if len(seq_df) > 0:\n",
                "    # ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ ì„ íƒ\n",
                "    longest_seq = seq_df.loc[seq_df['num_images'].idxmax()]\n",
                "    seq_path = Path(longest_seq['path'])\n",
                "    \n",
                "    print(f\"ìƒ˜í”Œ ì‹œí€€ìŠ¤: {seq_path.name}\")\n",
                "    print(f\"ì´ë¯¸ì§€ ìˆ˜: {longest_seq['num_images']}\")\n",
                "    \n",
                "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
                "    images = sorted(list(seq_path.glob('*.png')) + list(seq_path.glob('*.jpg')))\n",
                "    \n",
                "    # ê· ë“± ê°„ê²©ìœ¼ë¡œ 8ì¥ ì„ íƒ\n",
                "    indices = np.linspace(0, len(images)-1, 8, dtype=int)\n",
                "    \n",
                "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
                "    axes = axes.flatten()\n",
                "    \n",
                "    for ax, idx in zip(axes, indices):\n",
                "        img = cv2.imread(str(images[idx]))\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "        ax.imshow(img)\n",
                "        ax.set_title(f\"Frame {idx}\")\n",
                "        ax.axis('off')\n",
                "    \n",
                "    plt.suptitle(f\"KITTI Sequence: {seq_path.name}\", fontsize=14)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"ì‹œê°í™”í•  ì‹œí€€ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: ì—°ì† í”„ë ˆì„ ë¶„ì„ (Self-supervised í•™ìŠµìš©)\n",
                "\n",
                "def compute_frame_difference(img1, img2):\n",
                "    \"\"\"ë‘ í”„ë ˆì„ ê°„ ì°¨ì´ ê³„ì‚°\"\"\"\n",
                "    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜\n",
                "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
                "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
                "    \n",
                "    # ì°¨ì´ ê³„ì‚°\n",
                "    diff = cv2.absdiff(gray1, gray2)\n",
                "    mean_diff = np.mean(diff)\n",
                "    \n",
                "    return diff, mean_diff\n",
                "\n",
                "if len(seq_df) > 0:\n",
                "    # ìƒ˜í”Œ ì‹œí€€ìŠ¤\n",
                "    seq_path = Path(seq_df.iloc[0]['path'])\n",
                "    images = sorted(list(seq_path.glob('*.png')) + list(seq_path.glob('*.jpg')))[:100]\n",
                "    \n",
                "    # ì—°ì† í”„ë ˆì„ ì°¨ì´ ê³„ì‚°\n",
                "    differences = []\n",
                "    \n",
                "    for i in range(len(images) - 1):\n",
                "        img1 = cv2.imread(str(images[i]))\n",
                "        img2 = cv2.imread(str(images[i + 1]))\n",
                "        \n",
                "        if img1 is not None and img2 is not None:\n",
                "            _, mean_diff = compute_frame_difference(img1, img2)\n",
                "            differences.append(mean_diff)\n",
                "    \n",
                "    # ì‹œê°í™”\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
                "    \n",
                "    # í”„ë ˆì„ ê°„ ì°¨ì´ ê·¸ë˜í”„\n",
                "    axes[0].plot(differences)\n",
                "    axes[0].set_xlabel('Frame')\n",
                "    axes[0].set_ylabel('Mean Absolute Difference')\n",
                "    axes[0].set_title('Consecutive Frame Differences')\n",
                "    axes[0].axhline(np.mean(differences), color='red', linestyle='--', label=f'Mean: {np.mean(differences):.2f}')\n",
                "    axes[0].legend()\n",
                "    \n",
                "    # íˆìŠ¤í† ê·¸ë¨\n",
                "    axes[1].hist(differences, bins=30, alpha=0.7, edgecolor='black')\n",
                "    axes[1].set_xlabel('Mean Absolute Difference')\n",
                "    axes[1].set_ylabel('Count')\n",
                "    axes[1].set_title('Distribution of Frame Differences')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"\\nì—°ì† í”„ë ˆì„ ì°¨ì´ í†µê³„:\")\n",
                "    print(f\"  í‰ê· : {np.mean(differences):.2f}\")\n",
                "    print(f\"  í‘œì¤€í¸ì°¨: {np.std(differences):.2f}\")\n",
                "    print(f\"  ìµœì†Œ: {np.min(differences):.2f}\")\n",
                "    print(f\"  ìµœëŒ€: {np.max(differences):.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: Self-supervised í•™ìŠµìš© ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
                "\n",
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import torchvision.transforms as T\n",
                "\n",
                "class KITTISequenceDataset(Dataset):\n",
                "    \"\"\"\n",
                "    KITTI ì‹œí€€ìŠ¤ ë°ì´í„°ì…‹ (Self-supervised í•™ìŠµìš©)\n",
                "    \n",
                "    ì—°ì† í”„ë ˆì„ì„ positive pairë¡œ ì‚¬ìš©í•˜ëŠ” contrastive learningì— ì í•©\n",
                "    \n",
                "    ì°¸ê³ : SimCLR (Chen et al., 2020) - ê°™ì€ ì´ë¯¸ì§€ì˜ ë‹¤ë¥¸ augmentationì„ positive pairë¡œ ì‚¬ìš©\n",
                "    ì—¬ê¸°ì„œëŠ” ì—°ì† í”„ë ˆì„ë„ positive pairë¡œ í™œìš© ê°€ëŠ¥\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, sequence_dirs, transform=None, frame_gap=1):\n",
                "        \"\"\"\n",
                "        Args:\n",
                "            sequence_dirs: ì‹œí€€ìŠ¤ ë””ë ‰í† ë¦¬ ë¦¬ìŠ¤íŠ¸\n",
                "            transform: ì´ë¯¸ì§€ ë³€í™˜\n",
                "            frame_gap: ì—°ì† í”„ë ˆì„ ê°„ê²© (1=ë°”ë¡œ ë‹¤ìŒ í”„ë ˆì„)\n",
                "        \"\"\"\n",
                "        self.transform = transform\n",
                "        self.frame_gap = frame_gap\n",
                "        self.samples = []\n",
                "        \n",
                "        # ëª¨ë“  ì´ë¯¸ì§€ ìŒ ìˆ˜ì§‘\n",
                "        for seq_dir in sequence_dirs:\n",
                "            seq_path = Path(seq_dir)\n",
                "            images = sorted(list(seq_path.glob('*.png')) + list(seq_path.glob('*.jpg')))\n",
                "            \n",
                "            for i in range(len(images) - frame_gap):\n",
                "                self.samples.append((str(images[i]), str(images[i + frame_gap])))\n",
                "        \n",
                "        print(f\"ë°ì´í„°ì…‹ ìƒì„±: {len(self.samples):,}ê°œ í”„ë ˆì„ ìŒ\")\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.samples)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        img1_path, img2_path = self.samples[idx]\n",
                "        \n",
                "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
                "        img1 = cv2.imread(img1_path)\n",
                "        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        img2 = cv2.imread(img2_path)\n",
                "        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        # ë³€í™˜ ì ìš©\n",
                "        if self.transform:\n",
                "            img1 = self.transform(img1)\n",
                "            img2 = self.transform(img2)\n",
                "        \n",
                "        return img1, img2\n",
                "\n",
                "# SimCLR ìŠ¤íƒ€ì¼ ì¦ê°•\n",
                "simclr_transform = T.Compose([\n",
                "    T.ToPILImage(),\n",
                "    T.Resize((224, 224)),\n",
                "    T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
                "    T.RandomHorizontalFlip(p=0.5),\n",
                "    T.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
                "    T.RandomGrayscale(p=0.2),\n",
                "    T.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)),\n",
                "    T.ToTensor(),\n",
                "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "print(\"âœ… KITTISequenceDataset í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 8: Train/Val ë¶„í• \n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "if len(all_sequences) > 0:\n",
                "    # ì‹œí€€ìŠ¤ ë‹¨ìœ„ë¡œ ë¶„í•  (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)\n",
                "    train_seqs, val_seqs = train_test_split(\n",
                "        all_sequences, \n",
                "        test_size=0.2, \n",
                "        random_state=42\n",
                "    )\n",
                "    \n",
                "    print(f\"Train ì‹œí€€ìŠ¤: {len(train_seqs)}ê°œ\")\n",
                "    print(f\"Val ì‹œí€€ìŠ¤: {len(val_seqs)}ê°œ\")\n",
                "    \n",
                "    # ë°ì´í„°ì…‹ ìƒì„± (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ ì‘ì€ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸)\n",
                "    # ì‹¤ì œ í•™ìŠµ ì‹œì—ëŠ” ì „ì²´ ë°ì´í„° ì‚¬ìš©\n",
                "    sample_train_seqs = train_seqs[:min(5, len(train_seqs))]\n",
                "    \n",
                "    train_dataset = KITTISequenceDataset(\n",
                "        sequence_dirs=sample_train_seqs,\n",
                "        transform=simclr_transform\n",
                "    )\n",
                "    \n",
                "    # ë°ì´í„°ë¡œë” í…ŒìŠ¤íŠ¸\n",
                "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
                "    \n",
                "    # ìƒ˜í”Œ ë°°ì¹˜ í™•ì¸\n",
                "    img1_batch, img2_batch = next(iter(train_loader))\n",
                "    print(f\"\\në°°ì¹˜ shape: {img1_batch.shape}\")\n",
                "else:\n",
                "    print(\"ë¶„í• í•  ì‹œí€€ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 9: ì¦ê°•ëœ ì´ë¯¸ì§€ ìŒ ì‹œê°í™”\n",
                "\n",
                "def denormalize(tensor):\n",
                "    \"\"\"ImageNet ì •ê·œí™” ì—­ë³€í™˜\"\"\"\n",
                "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
                "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
                "    return tensor * std + mean\n",
                "\n",
                "if len(all_sequences) > 0 and 'train_dataset' in dir():\n",
                "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
                "    \n",
                "    for i in range(4):\n",
                "        img1, img2 = train_dataset[i * 100]\n",
                "        \n",
                "        # ì—­ì •ê·œí™”\n",
                "        img1_vis = denormalize(img1).permute(1, 2, 0).numpy()\n",
                "        img2_vis = denormalize(img2).permute(1, 2, 0).numpy()\n",
                "        \n",
                "        # í´ë¦¬í•‘\n",
                "        img1_vis = np.clip(img1_vis, 0, 1)\n",
                "        img2_vis = np.clip(img2_vis, 0, 1)\n",
                "        \n",
                "        axes[0, i].imshow(img1_vis)\n",
                "        axes[0, i].set_title(f\"Frame t\")\n",
                "        axes[0, i].axis('off')\n",
                "        \n",
                "        axes[1, i].imshow(img2_vis)\n",
                "        axes[1, i].set_title(f\"Frame t+1\")\n",
                "        axes[1, i].axis('off')\n",
                "    \n",
                "    plt.suptitle(\"Augmented Frame Pairs (SimCLR Style)\", fontsize=14)\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 10: ë°ì´í„°ì…‹ ì •ë³´ ì €ì¥\n",
                "\n",
                "import json\n",
                "\n",
                "# ë°ì´í„°ì…‹ ì •ë³´ ì €ì¥\n",
                "kitti_dataset_info = {\n",
                "    'total_sequences': len(all_sequences),\n",
                "    'total_images': int(seq_df['num_images'].sum()) if len(seq_df) > 0 else 0,\n",
                "    'train_sequences': len(train_seqs) if 'train_seqs' in dir() else 0,\n",
                "    'val_sequences': len(val_seqs) if 'val_seqs' in dir() else 0,\n",
                "    'sequence_paths': [str(s) for s in all_sequences],\n",
                "    'train_paths': [str(s) for s in train_seqs] if 'train_seqs' in dir() else [],\n",
                "    'val_paths': [str(s) for s in val_seqs] if 'val_seqs' in dir() else []\n",
                "}\n",
                "\n",
                "# ì €ì¥\n",
                "save_path = DATASET_ROOT / 'kitti_dataset_info.json'\n",
                "with open(save_path, 'w') as f:\n",
                "    json.dump(kitti_dataset_info, f, indent=2)\n",
                "\n",
                "print(f\"ë°ì´í„°ì…‹ ì •ë³´ ì €ì¥: {save_path}\")\n",
                "print(f\"\\n=\" * 50)\n",
                "print(\"KITTI ë°ì´í„° íƒìƒ‰ ì™„ë£Œ\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"ì´ ì‹œí€€ìŠ¤: {kitti_dataset_info['total_sequences']}\")\n",
                "print(f\"ì´ ì´ë¯¸ì§€: {kitti_dataset_info['total_images']:,}\")\n",
                "print(f\"\\në‹¤ìŒ ë‹¨ê³„: 04_ssl_pretraining.ipynb\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## KITTI ë°ì´í„°ì…‹ ìš”ì•½\n",
                "\n",
                "### ë°ì´í„° êµ¬ì¡°\n",
                "- ì—°ì† í”„ë ˆì„ ì´ë¯¸ì§€ ì‹œí€€ìŠ¤\n",
                "- ììœ¨ì£¼í–‰ ì‹œë‚˜ë¦¬ì˜¤ (ë„ë¡œ, ì°¨ëŸ‰, ë³´í–‰ì ë“±)\n",
                "\n",
                "### Self-supervised í•™ìŠµ ì „ëµ\n",
                "1. **ì—°ì† í”„ë ˆì„ í™œìš©**: ì‹œê°„ì ìœ¼ë¡œ ê°€ê¹Œìš´ í”„ë ˆì„ì€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬\n",
                "2. **Contrastive Learning**: ê°™ì€ ì‹œí€€ìŠ¤ì˜ í”„ë ˆì„ì€ positive pair\n",
                "3. **Data Augmentation**: SimCLR ìŠ¤íƒ€ì¼ ì¦ê°•ìœ¼ë¡œ ë‹¤ì–‘ì„± í™•ë³´\n",
                "\n",
                "### ì°¸ê³  ë…¼ë¬¸\n",
                "\n",
                "| ë…¼ë¬¸ | í•µì‹¬ ì•„ì´ë””ì–´ |\n",
                "|------|---------------|\n",
                "| KITTI (Geiger et al., 2012) | ììœ¨ì£¼í–‰ ë²¤ì¹˜ë§ˆí¬, ìŠ¤í…Œë ˆì˜¤ ì¹´ë©”ë¼, LiDAR, GPS ë°ì´í„° ì œê³µ |\n",
                "| SimCLR (Chen et al., 2020) | Contrastive learning, ê°•ë ¥í•œ augmentationìœ¼ë¡œ ë¼ë²¨ ì—†ì´ í‘œí˜„ í•™ìŠµ |\n",
                "| MoCo (He et al., 2020) | Momentum encoderë¡œ ì•ˆì •ì ì¸ contrastive learning |"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}